# Code-of-Echinococcus-granulosus-sensu-stricto-population-study

##Annotating VCF Files with SnpEff v4.3
#1. Modify the Configuration File. The configuration file that needs to be modified is located in the snpEff directory and is named snpEff.config. Open this file and add your custom database information on the last line.
$ echo "egl.genome:egl" >> snpEff.config
#2.Set Up the Database Path. Navigate to the SnpEff installation directory and create the necessary folders as follows:
$ cd snpEff
$ mkdir data
$ cd data
$ mkdir genomes
$ mkdir egl
#3. Organize Reference Genome and Annotation Files. Place the reference genome .fa file in the genomes folder and rename it to egl.fa. Also, place the GFF annotation file in the egl folder and rename it to genes.gff. The final file structure should look like this:
$ tree
.
├── genomes
│   └── egl.fa 
└── egl
    ├── genes.gff  # (or genes.gtf)

#4.Run the Script to Generate Bin Files. After preparing the files, return to the software directory and execute the following command to automatically generate the reference files. Check the directory containing the reference genome annotation files to see if .bin files have been created (the number of files corresponds to the number of chromosomes in the reference genome). The presence of these files indicates a successful build.
$ java -jar snpEff.jar build -gff3 -v egl -d -noCheckCds -noCheckProtein
#5. Run the Program to Perform Annotation. Execute the following command to annotate your VCF file:
$ snpEff egl vcf.gz > snpeff.vcf.gz
#Once the annotation is complete, snpEff_genes.txt and snpEff_summary.html files will be generated, containing summary information of the annotation. Additionally, a new VCF file with detailed annotation information will be created.

##Generating a thinned SNPs subset by selecting one variant within each 5 kb interval.
#1. Generate a List of Variant Positions Using a Custom Python Script. Use the following Python script to create a list of variant positions, selecting one variant every 5 kilobases (5kb) across the entire genome:
with open("whole_genome_SNPs.vcf", "r") as file: 
    lines = file.readlines()
    positions = []
    interval = 5000
    current_chrom = ""
    current_pos = 0
    for line in lines:
        if not line.startswith("#"):
            chromosome, pos, _ = line.split()[:3]
            pos = int(pos)
            if chromosome != current_chrom:
                current_chrom = chromosome
                current_pos = 0
            if pos - current_pos >= interval:
                current_pos = pos
                positions.append(f"{chromosome}\t{pos}")

with open("positions.txt", "w") as file:
    file.write("\n".join(positions))
#2. Use VCFtools to Generate the Subset VCF Dataset Based on the Position List
$vcftools --positions positions.txt --vcf whole_genome_SNPs.vcf --recode --out 5000step.vcf

##The SNPs of all samples in the thinned subset were converted into fasta sequences using vcf2phylip v2.8
$python vcf2phylip.py --input myfile.vcf --fasta

##Inferring a Neighbor-Joining (NJ) tree by phylip v3.698. Each program’s default output file is named outfile. To prevent confusion in subsequent analysis steps, it is necessary to rename the outfile from the previous step before proceeding to the next step.
#1.Generate bootstrap replicates from the input sequence alignment file.
$ phylip seqboot <input_alignment_file> <R> 1000 <Y> <9> 
$ mv outfile seqboot.out 
#2.Calculate genetic distances from the bootstrap replicates generated by seqboot.
$ phylip dnadist <seqboot.out> <M> D <100>
$ mv outfile dnadist.out
#3.Construct a phylogenetic tree using the neighbor-joining method based on the genetic distances calculated by dnadist.
$ phylip neighbor <dnadist.out> <M> 100 <9>
$ mv outfile neighbor.out
#4. Generate a consensus tree from the phylogenetic trees constructed by neighbor.
$ phylip consense <neighbor.out> <Y>

##PCA of the thinned subset was performed using PLINK v1.9
plink --vcf 5000step.vcf --pca 8 -out 5000step_plink

##Admixture analysis of the thinned subset was performed using block relaxation algorithm implemented in the ADMIXTURE v1.3.0 (78), with K values (number of hypothetical ancestral populations) ranging from 1 to 10.
$vcftools --vcf 5000step.recode.vcf --plink --out 5000step
$plink --allow-extra-chr --noweb --file 5000step --geno 0.05 --maf 0.05 --hwe 0.0001 --make-bed --out 5000step
$for K in 1 2 3 4 5 6 7 8 9 10; do admixture --cv 5000step.bed $K | tee log${K}.out; done

##VCFtools v0.1.15 was employed to calculate π, FST and F value.
$vcftools --gzvcf XXX.vcf.gz --keep popXX.txt --out pi_XX --window-pi 2000
$vcftools --vcf XXX.vcf --weir-fst-pop 1popXX.txt --weir-fst-pop 2popXX.txt --out pop1_VS_pop2 --fst-window-size 2000
$vcftools --vcf whole_genome_SNPs.vcf --het --out heterozygosity_results
##Calculate the absolute difference index (Dxy) between populations using pixy
$pixy --stats dxy --vcf XXX.vcf.gz --populations popXX-popXX.txt --window_size 2000 --n_cores 8  --bypass_invariant_check 'yes'

## Linkage disequilibrium decay was assessed using popLDdecay v3.42.
#Calculated for each population.
$PopLDdecay -InVCF file.vcf -OutStat XJ.stat.gz -SubPop XJ.txt
$PopLDdecay -InVCF file.vcf -OutStat QG.stat.gz -SubPop QG.txt
$PopLDdecay -InVCF file.vcf -OutStat XZ.stat.gz -SubPop XZ.txt
#plot Figure S8 by R.
library(ggplot2)
XJ_LD <- read.table("XJ.stat", header = TRUE)
QG_LD <- read.table("QG.stat", header = TRUE)
XZ_LD <- read.table("XZ.stat", header = TRUE)

XJ_LD$Group <- "XJ"
QG_LD$Group <- "QG"
XZ_LD$Group <- "XZ"

combined_LD <- rbind(XJ_LD, QG_LD, XZ_LD)

all_ld_plot <- ggplot(data = combined_LD, aes(x = Dist, y = Mean_r2, color = Group)) +
  geom_line(size = 1) +
  scale_color_manual(values = c("QG" = "#20B2AA", "XJ" = "#CD5C5C", "XZ" = "#6A5ACD")) +
  geom_hline(yintercept = 0.17, linetype = "dashed", color = "black", size = 1) + 
  geom_vline(xintercept = 4000, linetype = "dashed", color = "black", size = 1) + 
  labs(x = "Distance (kb)", y = "r²") +
  theme_classic() +
  theme(
    panel.border = element_rect(color = "black", fill = NA, size = 1.5), 
    axis.line = element_line(color = "black"), 
    axis.text = element_text(size = 16),
    axis.title = element_text(size = 18),
    plot.title = element_text(size = 20, face = "bold"),
    legend.position = c(0.95, 0.95),
    legend.justification = c("right", "top"),
    legend.title = element_blank(),
    legend.text = element_text(size = 14),
    axis.ticks = element_line(color = "black"),
    axis.ticks.length = unit(0.2, "cm")
  )

##The FastEPRR v2.0 (80) was used to calculate the genome-wide recombination rate along non-overlapping 50 kb windows for each population.Take Chr1 of pop QG as an example to show the code.
#Step1
>library(FastEPRR)
>FastEPRR_VCF_step1(vcfFilePath ="QG.recode.vcf", winLength = 50000, srcOutputFilePath="./QG/step1/chr1")
#Step2
>FastEPRR_VCF_step2(srcFolderPath = "./QG/step1", jobNumber = 1, currJob = 1,DXOutputFolderPath = "./QG/step2")
#Step3
>FastEPRR_VCF_step3(srcFolderPath = "./QG/step1", DXFolderPath = "./QG/step2", finalOutputFolderPath = "./QG/step3")
#Step4
>FastEPRR_rho2r(inputFilePath = "./QG/step3/chr1", outputFilePath = "./QG/rho2r/chr1", Ne = 100781)

##Count the number of Low-MAF sites for each sample.
#Calculate allele frequencies of all SNPs with VCFtools v0.1.15.
$vcftools --vcf whole_genome_SNPs.vcf --freq2 --out SNPs_freq
#Filter sites with MAF < 0.05 by python.
import pandas as pd

input_file = 'SNPs_freq.frq'
output_file = 'filtered_SNPs_freq.frq'

df = pd.read_csv(input_file, sep='\t', header=0)
print("list：", df.columns.tolist())

filtered_df = df[(df['FREQ1'] < 0.05) | (df['FREQ2'] < 0.05)]

filtered_df.to_csv(output_file, sep='\t', index=False)
#Generate bed file of Low-MAF sites by python
import pandas as pd
input_file = 'filtered_SNPs_freq.frq'
output_file = 'MAF0.05_SNPs.bed'

df = pd.read_csv(input_file, sep='\t')

new_df = pd.DataFrame({
    df.columns[0]: df.iloc[:, 0],
    'start': df.iloc[:, 1] - 1, 
    'end': df.iloc[:, 1]
})

new_df.to_csv(output_file, sep='\t', index=False)
#Split all samples into separate VCF files
INPUT_VCF="whole_genome_SNPs.vcf"

while read SAMPLE; do   
    vcftools --vcf "$INPUT_VCF" --indv "$SAMPLE" --recode --recode-INFO-all --out "$SAMPLE"
    mv "${SAMPLE}.recode.vcf" "${SAMPLE}.vcf"
    echo "Generated: ${SAMPLE}.vcf"
done < sampleID.txt
#Calculate the number of Low-MAF sites for each sample
echo -e "Sample_ID\tMAF_Count" > maf0.05_counts.txt
for sample_vcf in *.vcf; do
    sample_name=$(basename $sample_vcf .vcf)
    maf_count=$(bedtools intersect -u -a $sample_vcf -b MAF0.05_SNPs.bed | wc -l)
    echo -e "${sample_name}\t${maf_count}" >> maf0.05_counts.txt
done

##Calculate the total MAF of the heterozygous sites in the non-tandem repeat regions for each sample.
#Extract the sequencing depth information for the alternate and reference alleles at all heterozygous sites.
samples=$(bcftools query -l whole_genome_SNPs.vcf)

for sample in $samples; do
    bcftools query -i 'GT="het"' -f '%CHROM\t%POS\t[%GT]\t[%AD]\n' ${sample}.vcf > "${sample}_het_depths.txt"
done

#Remove heterozygous sites in tandem repeat regions
import os
import pandas as pd

input_directory = "./"  # Directory containing sampleID_het_depths.txt files
bed_file_path = "tandem_repeat_regions.bed"  # Path to the BED file containing repeat regions
output_directory = "./filtered_het_files/"  # Directory to save filtered files

os.makedirs(output_directory, exist_ok=True)

repeat_regions = pd.read_csv(
    bed_file_path, sep="\t", header=0, names=["chromosome", "start", "end"]
)

for filename in os.listdir(input_directory):
    if filename.endswith("_het_depths.txt"):
        sample_id = filename.split("_het_depths.txt")[0]
        file_path = os.path.join(input_directory, filename)

        df = pd.read_csv(
            file_path, sep="\t", header=None, names=["chromosome", "position", "genotype", "depths"]
        )
        def is_in_repeat(row):
            chr_filter = repeat_regions["chromosome"] == str(row["chromosome"])
            start_filter = repeat_regions["start"] <= row["position"]
            end_filter = repeat_regions["end"] >= row["position"]
            return (chr_filter & start_filter & end_filter).any()
        df_filtered = df[~df.apply(is_in_repeat, axis=1)]
        output_path = os.path.join(output_directory, f"{sample_id}_del_TE_het_depths.txt")
        df_filtered.to_csv(output_path, sep="\t", index=False, header=False)

print(f"Filtered files saved to: {output_directory}")

#Calculate the ratio of each heterozygous site
import os
import pandas as pd

input_directory = "./"  # Adjust as necessary if files are in a specific directory
output_file = "all_sample_Het_MAF_nonTE.txt"
results = []

for filename in os.listdir(input_directory):
    if filename.endswith("_del_TE_het_depths.txt"):
        sample_id = filename.split("_del_TE_het_depths.txt")[0]
        file_path = os.path.join(input_directory, filename)
        df = pd.read_csv(file_path, sep="\t", header=None, names=["chromosome", "position", "genotype", "depths"])
        df[['ref_depth', 'mut_depth']] = df['depths'].str.split(',', expand=True).astype(int)
        df['total_depth'] = df['ref_depth'] + df['mut_depth']
        df['minor_ratio'] = df[['ref_depth', 'mut_depth']].min(axis=1) / df['total_depth']
        
        # Filter conditions
        df_filtered = df[
            (df['total_depth'] >= 10) &             # Total depth >= 10
            (df['ref_depth'] >= 2) &                # Reference depth >= 2
            (df['mut_depth'] >= 2) &                # alternate depth >= 2
            (df['minor_ratio'] >= 0.05)             # Minor allele ratio >= 0.05
        ]
        
        # Calculate total depths for filtered data
        total_minor_depth = df_filtered[['ref_depth', 'mut_depth']].min(axis=1).sum()  # Sum of minor allele depths
        total_het_depth = df_filtered['total_depth'].sum()  # Total heterozygous depths
        # Calculate the ratio
        ratio = total_minor_depth / total_het_depth if total_het_depth > 0 else 0
        results.append([sample_id, ratio])

results_df = pd.DataFrame(results, columns=["sampleID", "Minor_Ratio"])
results_df.to_csv(output_file, sep="\t", index=False, header=True)

output_file

##Computing gene flow with Dsuite v0.5. For details, please refer to the website: https://github.com/millanek/tutorials/tree/master/analysis_of_introgression_with_snp_data
$Dsuite Dtrios -c -n geneflow -t tree_replaced.nwk whole_genome_SNPs.vcf.gz pop_set.txt
$Dsuite Fbranch tree_replaced.nwk geneflow_tree.txt -p 0.05 > geneflow_tree_Fbranch.txt
#Draw Figure S15.
$ruby plot_d.rb geneflow_BBAA.txt plot_order.txt 0.08 geneflow_BBAA_D.svg
$ruby plot_f4ratio.rb geneflow_BBAA.txt plot_order.txt 0.2 geneflow_BBAA_f4ratio.svg
#Draw Figure S16.
python3 ./Dsuite/Dsuite/utils/dtools.py geneflow_tree_Fbranch.txt tree_replaced.nwk

##Analyze historical effective population size using SMC++ v1.15.2.
#Convert VCF to the SMC++ input format with vcf2smc:
for popid in `awk '{print $2}' id2loc.tsv | sort | uniq`
do
cat chr2len_withchrid.tsv | while read -r chrid chr len
do
    echo $popid
    poplist=`cat id2loc.tsv | grep $popid | awk '{printf $1","}' | sed 's/,$/\n/'`
    popstr="${popid}:$poplist"

    echo "smc++ vcf2smc $PWD/Eg_final_ChrOnly.vcf.gz  $PWD/data/${popid}.$chrid.smc.gz $chr --length $len $popstr" > vcf2smc_qsub/$popid.$chrid.vcf2smc.sh
    qsub -clear -wd $PWD/vcf2smc_qsub -q pathogendb.q -l vf=16g,p=1 -binding linear:1 vcf2smc_qsub/$popid.$chrid.vcf2smc.sh
done
done
#Inferred effective population size (Ne) over time for the three populations using subcommand cv in SMC++ with default 100bp window size.
for popid in `awk '{print $2}' id2loc.tsv | sort | uniq`
do
    echo $popid
    echo "smc++ cv -o $PWD/CV_output_rerun/${popid}_result 2.31e-9 $PWD/data/${popid}.*.smc.gz  --knots 18 --cores 48" > smcpp_cv_rerun_qsub/$popid.smcpp_cv.sh
    qsub -clear -wd $PWD/smcpp_cv_rerun_qsub -q pathogendb.q -l vf=32g,p=48 -binding linear:24 smcpp_cv_rerun_qsub/$popid.smcpp_cv.sh
done

##Calculate nSL and XP-nSL using Selscan v2.0.
#XP-nSL between populations
for k in  1 2 3 4 5 6 7 8 9;
do selscan --xpnsl \
	   --vcf pop1.chr${k}.recode.vcf \
	   --vcf-ref pop2.chr${k}.recode.vcf \
	   --out pop2_pop1_XPNSL.chr${k} --threads 16;
done
#Standardized according to 2kb windows
for k in  1 2 3 4 5 6 7 8 9;
do norm --xpnsl \
        --files  chr.pop2_pop1_XPNSL.chr${k}.xpnsl.out \
        --bp-win --winsize 2000;
done

#nSL of each populations
for k in 1 2 3 4 5 6 7 8 9; 
do selscan --nsl \
           --vcf whole_genome.chr${k}.recode.vcf \
           --threads 16 \
           --out  whole_genome.chr${k}.nsl;
done 
#Standardized according to 2kb windows
for k in  1 2 3 4 5 6 7 8 9;
do norm --nsl \
        --files  whole_genome.chr${k}.nsl.out \
        --bp-win --winsize 2000;
done
##Calculate Tajima’s D of each population or all dataset using VCFtools v0.1.15.
vcftools --gzvcf XXX.vcf.gz --keep pop_XXX.txt --out TajimaD_XXX --TajimaD 2000

##The intersect subroutine of bedtools filters the intersection of the selective windows with the genome gff annotation file.
$bedtools intersect -wa -a Eg_gene.gff -b selective_windows.txt > selective_gene_overlap.gff

##GO and KEGG enrichment analysis of selective genes.
setwd("./")
library(clusterProfiler)
pathway2description <- read.delim('Eukaryotes_ko_decription_uniq.tsv', stringsAsFactors=FALSE)
gene2pathway <- read.delim('gene_Pathway.tsv', stringsAsFactors=FALSE)
GO2description <- read.delim('go.tb', stringsAsFactors=FALSE)
gene2GO <- read.delim('gene_GO_class.txt', stringsAsFactors=FALSE)
gene_list <- read.delim('selective_genes.txt',header=F, stringsAsFactors=FALSE)

gene2GO = split(gene2GO, with(gene2GO, class))

mf_go <- enricher (gene_list[,1], pvalueCutoff = 0.05, pAdjustMethod = "BH", TERM2GENE=gene2GO[['molecular_function']][c(2,1)], TERM2NAME=GO2description[1:2])
cc_go <- enricher (gene_list[,1], pvalueCutoff = 0.05, pAdjustMethod = "BH", TERM2GENE=gene2GO[['cellular_component']][c(2,1)], TERM2NAME=GO2description[1:2])
bp_go <- enricher (gene_list[,1], pvalueCutoff = 0.05, pAdjustMethod = "BH", TERM2GENE=gene2GO[['biological_process']][c(2,1)], TERM2NAME=GO2description[1:2])

kegg_enricher <- enricher(gene_list[,1], pvalueCutoff = 0.05, pAdjustMethod = "BH", TERM2GENE=gene2pathway[c(2,1)], TERM2NAME=pathway2description[1:2])

rbind_go <- rbind(mf_go@result, 
                  cc_go@result, 
                  bp_go@result)
rbind_go$class <- c(rep("molecular_function", nrow(mf_go@result)),
                    rep("cellular_component", nrow(cc_go@result)),
                    rep("biological_process", nrow(bp_go@result)))
sig_rbind_go <- rbind_go[rbind_go$pvalue < 0.05, ]
sig_rbind_go <- data.frame(sig_rbind_go, header= T, stringsAsFactors = F)

kegg_result <- data.frame(kegg_enricher@result, header= T, stringsAsFactors = F)
sig_kegg <- kegg_result[kegg_result$pvalue < 0.05, ]

##Mapping partial genomic LD regions.
$./LDBlockShow-master/bin/LDBlockShow   -InVCF chr9.vcf -OutPut LD_ECG_09652 -Region 9:4175249:4185008  -InGFF ECG_09652.gff -OutPdf -SeleVar 2 -ShowNum -SpeSNPName Spe.snp

##The rehh v3.2.2 in R was employed to plot haplotype decay for the sites under linked selection.
library(rehh)

hhh <- data2haplohh(hap_file = "chr9.vcf",
                   polarize_vcf = FALSE,
                   vcf_reader = "data.table")

res <- calc_ehh(hhh, 
                mrk = "r24067", 
                include_nhaplo = TRUE)
plot(res)

##BalLeRMix v2.2 was used to calculate the B2 statistics for the non-overlapping 2 kb windows.
#Prepare input file by python
import pandas as pd

def process_vcf(vcf_path, output_path):
    vcf_df = pd.read_csv(vcf_path, sep='\t', header=None, comment='#')
    physPos = vcf_df[1]
    genPos = physPos / 1000000
    genotypes = vcf_df.iloc[:, 9:]
    n_ones = genotypes.apply(lambda row: row.str.count('1').sum(), axis=1)
    n_total = len(genotypes.columns) * 2
    n_ones = n_ones.apply(lambda x: min(x, n_total - x))
    result_df = pd.DataFrame({'physPos': physPos, 'genPos': genPos, 'x': n_ones, 'n': n_total})

    result_df.to_csv(output_path, sep='\t', index=False)
vcf_file_path = 'beagle.chrXXX.recode.vcf'
output_file_path = 'chrXXX.min.txt'
process_vcf(vcf_file_path, output_file_path)
#Calculate B2 statistics for each chromosome.
$python BalLeRMix_v2.5.py -i chrXXX.min.txt --getSpect --MAF --spect chrXXX.spect.txt
$python BalLeRMix_v2.5.py -i chrXXX.min.txt --MAF --spect chr9.spect.txt -o chrXXX.b2.txt
